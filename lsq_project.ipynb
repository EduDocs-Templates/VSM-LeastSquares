{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:06.281795Z",
     "start_time": "2018-11-12T05:37:06.185875Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from scipy.sparse import coo_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "from lsq_code import remove_outlier, create_vandermonde, solve_linear_LS, solve_linear_LS_gd, mnist_pairwise_LS\n",
    "\n",
    "# Other possibly useful functions\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "When $n=1$, we can fit a degree-$m$ polynomial by choosing $f_{j}(x)=x^{j-1}$ and $M=m+1$. \n",
    "In this case, it follows that $A_{i,j}=x_{i}^{j-1}$\n",
    "and the matrix $A$ is called a Vandermonde matrix.\n",
    "Write a function to create Vandermonde matrix **(5 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:06.293104Z",
     "start_time": "2018-11-12T05:37:06.284399Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(1, 10)\n",
    "create_vandermonde(x, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write a function to solve least-square problem via linear algebra **(5 pt)**\n",
    "\n",
    "Implementation hint: check `numpy.linalg.lstsq`.\n",
    "\n",
    "Using the setup in the previous example, try fitting the points $(1,2),(2,3),(3,5),(4,7),(5,11),(6,13)$\n",
    "to a degree-2 polynomial.\n",
    "\n",
    "Print the mean squared error. **(5 pt)**\n",
    "\n",
    "Plot this polynomial (for $x\\in[0,7]$) along with the data points to see the quality of fit. **(5 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:06.945113Z",
     "start_time": "2018-11-12T05:37:06.303310Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6])\n",
    "y = np.array([2, 3, 5, 7, 11, 14])\n",
    "m = 2\n",
    "\n",
    "# Create Vandermonde matrix A\n",
    "A = \n",
    "\n",
    "# Use linear algebra to solve least-squares problem and minimize || y - A z ||^2\n",
    "z_hat = \n",
    "\n",
    "# Compute the minimum square error\n",
    "mse = \n",
    "\n",
    "# Generate x/y plot points for the fitted polynomial\n",
    "xx = np.linspace(0, 7)\n",
    "yy = \n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x, y, color='red', label='data points')\n",
    "plt.plot(xx, yy, linestyle='dotted',label='normal equation poly fit')\n",
    "plt.legend()\n",
    "\n",
    "poly1_expr = ' + '.join(['{0:.4f} x^{1}'.format(v, i) for i, v in enumerate(z_hat)][::-1])[:-4]\n",
    "print('normal equation polynomial fit is {0}'.format(poly1_expr))\n",
    "print('normal equation MSE is {0:.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Write a function to solve a least-squares problem via gradient descent. **(5 pt)**\n",
    "\n",
    "Print the mean squared error. **(5 pt)**\n",
    "\n",
    "Plot the resulting polynomial (for $x\\in[0,7]$) along with previous polynomial and original data points to see the quality of fit. **(5 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gradient descent to solve least-squares problem and minimize || y - A z2 ||^2\n",
    "z2_hat = \n",
    "\n",
    "# Compute the minimum square error\n",
    "mse2 = \n",
    "\n",
    "# Generate y plot points for the gd fitted polynomial\n",
    "yy2 =\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x, y, color='red', label='data points')\n",
    "plt.plot(xx, yy, linestyle='dotted',label='normal equation poly fit')\n",
    "plt.plot(xx, yy2, linestyle='dashed', label='gradient descent poly fit')\n",
    "plt.legend()\n",
    "\n",
    "poly2_expr = ' + '.join(['{0:.4f} x^{1}'.format(v, i) for i, v in enumerate(z2_hat)][::-1])[:-4]\n",
    "print('gradient descent polynomial fit is {0}'.format(poly2_expr))\n",
    "print('gradient descent MSE is {0:.4f}'.format(mse2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST\n",
    "\n",
    "Read `mnist_train.csv`, create a dataframe with two columns, column `feature` contains all $x$ and column `label` contains all $y$.\n",
    "\n",
    "Plot the first 30 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mnist csv file to a dataframe\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "# append feature column by merging all pixel columns\n",
    "df['feature'] = df.apply(lambda row: row.values[1:], axis=1)\n",
    "# only keep feature and label column\n",
    "df = df[['feature', 'label']]\n",
    "# display first 5 rows of the dataframe\n",
    "df.head()\n",
    "\n",
    "# Plot the first 30 images\n",
    "plt.figure(figsize=(15, 2.5))\n",
    "for i, row in df.iloc[:30].iterrows():\n",
    "    x, y = row['feature'], row['label']\n",
    "    plt.subplot(2, 15, i + 1)\n",
    "    plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Write the function `extract_and_split` to extract the all samples labeled with digit $n$ and randomly separate fraction of samples into training and testing groups. **(10 pt)**\n",
    "\n",
    "Implementation hint: check `sklearn.model_selection.train_test_split`.\n",
    "\n",
    "Pairwise experiment for applying least-square to classify digit $a$ and digit $b$. \n",
    "\n",
    "Follow the given steps in the template and implement the `mnist_pairwise_LS` function for pairwise experiment **(15 pt)**\n",
    "\n",
    "Possible implementation hint: check `sklearn.metrics.accuracy_score`, `sklearn.metrics.confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:16.355345Z",
     "start_time": "2018-11-12T05:37:14.938389Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pairwise experiment for LSQ to classify between 0 and 1\n",
    "mnist_pairwise_LS(df, 0, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Repeat the above problem for all pairs of digits. For each pair of digits, report the classification error rates for the training and testing sets. The error rates can be formatted nicely into a triangular matrix.  Put testing error in the lower triangle and training error in the upper triangle.\n",
    "\n",
    "The code is given here in order demonstrate tqdm.\n",
    "Points awarded for reasonable values **(10 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:38:04.023889Z",
     "start_time": "2018-11-12T05:37:44.453306Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "num_trial, err_matrix = 1, np.zeros((10, 10))\n",
    "for a, b in tqdm(it.combinations(range(10), 2), total=45):\n",
    "    err_tr, err_te = np.mean([mnist_pairwise_LS(df, a, b) for _ in range(num_trial)], axis=0)\n",
    "    err_matrix[a, b], err_matrix[b, a] = err_tr, err_te\n",
    "\n",
    "print(np.round(err_matrix*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "But, what about a multi-class classifier for MNIST digits? \n",
    "For multi-class linear classification with d classes, one standard approach is to learn a linear mapping $f \\colon \\mathbb{R}^n \\to \\mathbb{R}^d $ where the “$y$”-value for the $i$-th class is chosen to be the standard basis vector $ \\underline{e}_i \\in \\mathbb{R}^d $. \n",
    "This is sometimes called one-hot encoding. \n",
    "Using the same $A$ matrix as before and a matrix $Y$, defined by $Y_{i,j}$ if observation $i$ in class $j$ and $Y_{i,j} = 0$ otherwise, we can solve for the coefficient matrix $Z \\in \\mathbb{R}^d$ coefficients .\n",
    "Then, the classifier maps a vector $\\underline{x}$ to class $i$ if the $i$-th element of $Z^T \\underline{x}$ is the largest element in the vector. \n",
    "\n",
    "Follow the steps in the template and implement the multi-class classification experiment **(20 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:38:10.540579Z",
     "start_time": "2018-11-12T05:38:08.739216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly split into training/testing set\n",
    "tr, te = \n",
    "\n",
    "# Construct the training set\n",
    "X_tr = \n",
    "y_tr =\n",
    "\n",
    "# Construct the testing set\n",
    "X_te = \n",
    "y_te =\n",
    "\n",
    "# Apply one-hot encoding to training labels\n",
    "Y = \n",
    "\n",
    "# Run least-square on training set\n",
    "Z =\n",
    "\n",
    "# Compute estimation and misclassification on training set\n",
    "y_hat_tr = \n",
    "err_tr =\n",
    "\n",
    "# Compute estimation and misclassification on training set\n",
    "y_hat_te =\n",
    "err_te =\n",
    "\n",
    "print('training error = {0:.2f}%, testing error = {1:.2f}%'.format(100 * err_tr, 100 * err_te))\n",
    "# Compute confusion matrix\n",
    "cm = np.zeros((10, 10), dtype=np.int64)\n",
    "for a in range(10):\n",
    "    for b in range(10):\n",
    "        cm[a, b] = ((y_te == a) & (y_hat_te == b)).sum()\n",
    "print('Confusion matrix:\\n {0}'.format(cm))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "309px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
